{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankitom\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the wisconsin breast cancer dataset\n",
    "df = pd.read_csv('wdbc.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1      2      3      4       5        6        7       8        9   \\\n",
       "0  842302  M  17.99  10.38  122.8  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "1  842517  M  20.57  17.77  132.9  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "\n",
       "    ...        22     23     24      25      26      27      28      29  \\\n",
       "0   ...     25.38  17.33  184.6  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1   ...     24.99  23.41  158.8  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preparing Data for the pipeline\n",
    "X = df.loc[:,2:].values\n",
    "y = df.loc[:,1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoder has assigned 0 to Benign and 1 to Malignant class type\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction | PCA\n",
    "PCA: Principal component analysis.\n",
    "\n",
    "Data is transformed into a low/equal dimensional feature subspace such that principal components(directions of maximum variance) are orthogonal to each other.\n",
    "\n",
    "PCA helps us to identify patterns in data based on the correlation between features.\n",
    "\n",
    "PCA aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions that the original one. \n",
    "\n",
    "The orthogonal axes (principal components) of the new subspace can be interpreted as the directions of maximum variance given the constraint that the new feature axes are orthogonal to each other.\n",
    "\n",
    "## Using PCA for dimensionality reduction with 10 PCs, play around with PCs and see the accuracies you get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "The Pipeline object takes a list of tuples as input, where the first value in each tuple is an arbitrary identifier string that we can use to access the individual elements in the pipeline, and the second element in every tuple is a scikit-learn transformer or estimator.\n",
    "\n",
    "The intermediate steps in a pipeline constitute scikit-learn transformers, and the last step is an estimator.\n",
    "\n",
    "![Pipeline](working_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Pipeline\n",
    "\n",
    "lr_pipe = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=10)),\n",
    "                    ('clf',LogisticRegression(random_state=1))])\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Test Accuracy: %.3f' % lr_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "# SVM pipeline\n",
    "svm_pipe = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=10)),\n",
    "                     ('clf', SVC())])\n",
    "\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Test Accuracy: %.3f' % svm_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Mean score: 0.9799862401100792\n"
     ]
    }
   ],
   "source": [
    "# Performing K fold Cross Validation to get an estimate of model performance on unknown data.\n",
    "print('Logistic Regression Mean score: {}'.format(cross_val_score(estimator=lr_pipe, \n",
    "                                                                  X=X_train, y= y_train,\n",
    "                                                                  cv=25, n_jobs = -1).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Mean score: 0.96640522875817\n"
     ]
    }
   ],
   "source": [
    "print('SVM Mean score: {}'.format(cross_val_score(estimator=svm_pipe, \n",
    "                                                                  X=X_train, y= y_train,\n",
    "                                                                  cv=25, n_jobs = -1).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comments | Conclusion | Observations\n",
    "\n",
    "## Dimensionality Reduction: \n",
    "    Out of 30 features in the original dataset 10 Principal components cover the most info.\n",
    "    We have reduced the problem from 30 Dims to 10 Dims.\n",
    "    \n",
    "## Pipeline\n",
    "\n",
    "    It saved us a lot of steps and made the process simpler. \n",
    "    \n",
    "    Without having to write fit_transform on data for standardization and then passing that \n",
    "    data for pca and again writing fit_transform for PCA and then repeating the same for estimator.\n",
    "    \n",
    "    We just instantiated a pipeline with necessary transformations and estimator and that does it all. \n",
    "    \n",
    "    Now our Pipeline acted as an trained estimator just like any other estimator logistic regression\n",
    "    or svm but it also internally performed scaling and dimensionality reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Cross Validation\n",
    "\n",
    "    Obtain reliable estimates of the model's generalization error, that is, how well the\n",
    "    model performs on unseen data.\n",
    "\n",
    "    In k-fold cross-validation, we randomly split the training dataset into k folds \n",
    "    without replacement, where k-1 folds are used for the model training and one fold\n",
    "    is used for testing. This procedure is repeated k times so that we obtain k models\n",
    "    and performance estimates.\n",
    "\n",
    "    We then calculate the average performance of the models based on the different, \n",
    "    independent folds to obtain a performance estimate that is less sensitive to \n",
    "    the subpartitioning of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

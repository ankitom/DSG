{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "1. Supervised: Induction --> Specifics to generalization.\n",
    "2. Unsupervised: Finding structure in the data, description.  \n",
    "3. Reinforcement: Getting a feedback and learning from that.\n",
    "\n",
    "## Combination of unsupervised and supervised learnings can do wonders.\n",
    "Data -> Unsupervised learning --> labels --> Supervised learning --> Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Bayes Rule: \n",
    "\n",
    "P(c) = Probability of cancer(event occuring). (Prior Probability)\n",
    "\n",
    "Test evidence:\n",
    "P(pos/c) = Probability that test is positive when cancer is there. -- Sensitivity (SENACPO)\n",
    "P(pos/-c) = Probability that test is negative when cancer is not there. -- Specificity (SPACNE)\n",
    "\n",
    "Remember:\n",
    "\n",
    "SENACPO -- Number of times we are correct when ACtual value is POsitive.\n",
    "SPACNE  -- Number of times we are correct when ACtual value is NEgative. \n",
    "\n",
    "BAYES RULE:\n",
    "\n",
    "(PRIOR PROB) . (TEST EVIDENCE) -> (POSTERIOR PROB)\n",
    "\n",
    "P(c) = 0.01 (1%)  |  P(-c) = 0.99 (99%)\n",
    "\n",
    "SENSITIVITY: P(pos/c) = 0.9 (90%) | P(neg/c) = 0.1 (10%)\n",
    "\n",
    "SPECIFICITY: P(neg/-c) = 0.9 (90%)| P(pos/-c) = 0.1 (10%) \n",
    "\n",
    "\n",
    "JOINT PROB :\n",
    "\n",
    "P(c/pos) = P(c) . P(pos/c) = 0.01 x .90 = 0.009\n",
    "\n",
    "P(-c/pos) = P(-c) . P(pos/-c) = 0.99 x 0.1 = 0.099\n",
    "\n",
    "\n",
    "joint Probabilities generally dont add up to 1. Normalize them to make them add upto 1. \n",
    "\n",
    "(Normalizer)factor = P(c/pos) + P(-c/pos) = 0.108\n",
    "\n",
    "ACTUAL POSTERIOR PROB:\n",
    "\n",
    "P(c/pos) = 0.009/factor = 0.08333 (8.33%)\n",
    "\n",
    "P(-c/pos) = 0.099/factor = 0.9166 (91.67%)\n",
    "\n",
    "P(c/pos) + P(-c/pos) = 0.0833 + 0.9166 = 1.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Uses of Naive Bayes:\n",
    "    \n",
    "### It is used a lot for text learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Naive? \n",
    "\n",
    "Ignores word order, only considers the frequency of words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strengths and Weaknesses\n",
    "\n",
    "Strengths:\n",
    "1. Can handle lots of words (features) 20k and more.\n",
    "2. Easy to implement.\n",
    "\n",
    "Weakness:\n",
    "1. Ignores word order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVM - Support Vector Machine\n",
    "\n",
    "Finds a hyperplane/line(2d) which separates the classes being at max distance from the nearest datapoints of the classes. \n",
    "\n",
    "The distance at which hyplane or line is from the nearest point is called MARGIN.\n",
    "\n",
    "Best Hyperplane/line is the one which maximizes the margin from classes and has most correct classifications. Priority of SVM is correct classification then margin. \n",
    "\n",
    "Tolerates outliers easily. Robust to outliers.\n",
    "\n",
    "## Non Linear SVMs\n",
    "\n",
    "Adding a feature from mathematical combination of existing features e.g z = x^2 + y^2 or z = |x| finds a hyperplane where it's impossible to separate classes linearly using original features.\n",
    "\n",
    "Uses kernels to tap high dimensional space to convert non linearly separable variables in low dimension, finds a hyperplane in high dimension and returns the solution to lower dimension in form of a non linear separator.\n",
    "\n",
    "### Parameters in SVM\n",
    "\n",
    "Kernel = rbf, sigmoid, poly , custom, linear etc.\n",
    "\n",
    "Gamma = radial influence of single data point low gamma meaning far influence, high gamma meaning close influence. \n",
    "The 'gamma' parameter actually has no effect on the 'linear' kernel for SVMs. The key parameter for this kernel function is \"C\".\n",
    "\n",
    "C = Controls the tradeoff between simple decision boundary and correctly classifying training points.\n",
    "Larger the C more the correct classifications, lower the C simpler the decision boundary.\n",
    "\n",
    "Overfitting can be controlled by parameters of the algo, for example in case of SVMs C, Gamma, Kernel.\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "Memory efficient as uses only subset of training points.\n",
    "Performs well in high dimensional data.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "Doesn't perform well with lots and lots of data as order is n^3.\n",
    "Doesn't work well with lots of noise.\n",
    "Very slow compared to Naive Bayes.\n",
    "\n",
    "\n",
    "# SVM tips:\n",
    "\n",
    "1. Changing kernel can improve accuracy drastically eg. rbf - 48% to linear - 97%.\n",
    "2. Reducing sample size increases training and prediction speed but reduces testing accuracy.\n",
    "3. SVMs do not scale well. (O(n) = n^2 , quadratic order)\n",
    "4. Optimized rbf 99% , linear 97%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "creates linear decision boundaries.\n",
    "\n",
    "# Parameters\n",
    "\n",
    "min_samples_split = 2(Default)\n",
    "Means won't split if samples at a node < min_sample_split \n",
    "\n",
    "More the min_samples_split, lesser the splits, lesser the complexity, lesser the overfitting.\n",
    "\n",
    "# Entropy - \n",
    "## Measure of impurity in a bunch of examples.\n",
    "\n",
    "Purity: Having all examples of the same class in a splitted section. \n",
    "\n",
    "Entropy/impurity: Having more than 1 examples of other class at a node.\n",
    "\n",
    "Entropy is defined for a node. A node might have multiple classes and thus entropy\n",
    "if a node has only one class, it is a pure node and entropy is 0. \n",
    "\n",
    "Entropy = 1.0 when examples are evenly split amongst classes.\n",
    "Entropy = 0 when only one class is present in a split. Pure !\n",
    "\n",
    "Objective: Minimizing impurity in splitting.\n",
    "\n",
    "Entropy = −∑\n",
    "​i\n",
    "​​ (p\n",
    "​i\n",
    "​​ )log\n",
    "​2\n",
    "​​ (p\n",
    "​i\n",
    "​​ )\n",
    "\n",
    "where, i is a class and pi is % of that class in the split. \n",
    "\n",
    "## Information Gain\n",
    "\n",
    "Gain = entropy(parent) - [weighted average]entropy(children)\n",
    "\n",
    "[weighted average] is calculated basis proportion of samples going in a split.\n",
    "exam 2/3 and 1/3\n",
    "\n",
    "More Gain, lesser entropy in children, more purity, better classification. Objective: Maximize Gain.\n",
    "Decision trees maximize gain.\n",
    "\n",
    "## Gini and Entropy:\n",
    "sklearn has two criterion namely gini and entropy. Default is gini. \n",
    "\n",
    "# Bias Variance Trade-off\n",
    "\n",
    "Bias: \n",
    "\n",
    "1. A high bias ml algo doesn't learn anything from data, practically ignores it. \n",
    "2. Pays little attention to data.\n",
    "3. High error on training set (low Rsquared, high SSE)\n",
    "4. Oversimplified\n",
    "\n",
    "Variance: Willingness and flexibility of an algo to learn. \n",
    "\n",
    "1. A high variance ml algo is highly susceptive to data and can't generalize. \n",
    "2. Memorizes the data.\n",
    "3. Fails to generalize well.\n",
    "4. Much Higher error on testing set (low Rsquared, high SSE)\n",
    "5. Overfitting\n",
    "\n",
    "In stats : Variance means spread of a data distribution.\n",
    "\n",
    "## Underfit -High bias ----> Good Model ----> Overfit High Variance\n",
    "## Finding the optimal number of features for the good model which balances bias and variance. Can be done by:\n",
    "\n",
    "1. Regularization: Penalizes for extra features.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Decision Tree :\n",
    "Strengths: Can make bigger classifiers(Ensembled Methods).\n",
    "\n",
    "Weakness: Overfitting. (Be careful about parameter tuning). \n",
    "\n",
    "# Reducing complexity of algorithms and improving speed\n",
    "\n",
    "1. Tune parameters\n",
    "2. Identify necessary features and only use them for building model. \n",
    "(Generally more features the algo has, the more complex it is for fitting)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Entropy calculator\n",
    "from math import log2\n",
    "def entrocalc(class_samples):\n",
    "    entropy = 0\n",
    "    tot_samples = 0\n",
    "    for val in class_samples:\n",
    "        tot_samples += class_samples[val]\n",
    "    \n",
    "    for key in class_samples:\n",
    "        pi = class_samples[key]/(tot_samples)\n",
    "        entropy = entropy - (pi)*log2(pi)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# More Data Better Results \n",
    "(Generally) better than even a super optimized algo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Types of Data\n",
    "\n",
    "1. Numerical: Numbers like 234, 453.0 etc ex. age, height, score.\n",
    "\n",
    "2. Categorical: Discrete values like gender, color, material, job title etc\n",
    "\n",
    "3. TimeSeries: Temporal data (timestamp)\n",
    "\n",
    "4. Text: Words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Be very careful about introducing features that come from different sources depending on the class! It’s a classic way to accidentally introduce biases and mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression (Continuous output)\n",
    "\n",
    "Minimizes sum of squared errors (actual - predicted). \n",
    "Finds slope and intercept for the line which minimizes sum of squared errors.\n",
    "\n",
    "absolute error minimization not used because it can give us more than one lines. \n",
    "\n",
    "In case of squared errors there will be only one line. also SSE is easier to implement. \n",
    "## Problem with SSE:\n",
    "1. Adding more data increases SSE but that doesn't mean fit is bad.\n",
    "\n",
    "\n",
    "This is done by:\n",
    "\n",
    "Ordinary Least squares OLS (used in sklearn)\n",
    "\n",
    "Linear descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measure for Regression : R-Squared\n",
    "\n",
    "R-Squared: \"How much of change in the output is explained by the change in the input.\n",
    "\n",
    " 0.0 < R-Squared < 1.0 (Best)\n",
    " \n",
    "Negative R-Squared is possible.*\n",
    "\n",
    "Advantage over SSE:\n",
    "1. Independent of datapoints. \n",
    "Higher the R-Squared, the better. Max value = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Always visualize your data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare data points which don't follow the trend.\n",
    "\n",
    "Causes:\n",
    "1. Sensor Malfunction - to be ignored\n",
    "2. Data entry errors - to be ignored  \n",
    "3. Freak events: - to be paid attention to.  e.g. Fraud detection\n",
    "\n",
    "Removal:\n",
    "\n",
    "1. Train > 2.Remove(10% with max residual error) > 3.Train again\n",
    "\n",
    "(Repeat steps 2 & three until satisfied)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization is one of the most powerful tools for finding outliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# First thing to do is to Identify and Clean the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K means clustering\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Assign: Randomly assign cluster centers.\n",
    "2. Cluster Identification: Find points nearest to these cluster centers to identify the clusters. \n",
    "3. Centroid :Find the centroid of these clusters. New cluster centers are these centroids.\n",
    "4. Repeat 2 & 3 until cluster centers stop updating.\n",
    "\n",
    "\n",
    "sklearn params:\n",
    "\n",
    "n_clusters = Number of clusters we want to have.\n",
    "n_init = How many times it is initialized. Play with this if you see clustering getting affected by initialization. \n",
    "\n",
    "max_iter = How many iterations in total?\n",
    "\n",
    "\n",
    "Limitations :\n",
    "\n",
    "1. Premature convergence to sub optimal values. \n",
    "2. Can result into different clusters based on Initialization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling :\n",
    "\n",
    "Rescaling the features such that they are on the same scale and have equal influence on the results.\n",
    "\n",
    "X' = (X - Xmin)/(Xmax - Xmin)\n",
    "\n",
    "Before scaling REMOVE THE OUTLIERS coz OUTLIERS WILL MESS WITH SCALING.\n",
    "\n",
    "sklearn's minmaxscaler\n",
    "\n",
    "## Algorithms which involve two or more dimensions will be affected by feature scaling. \n",
    "But since in regression features go with coefficients which take care of scale of that feature. \n",
    "Also in decision trees decision boundaries are always vertical or horizontal rendering it unaffected by the size of of different features. \n",
    "Kmeans and SVMs will be affected by scaling coz distance calculation is involved with different dimensions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning From Text\n",
    "\n",
    "Bag of Words: Frequency counts of occuring words.\n",
    "\n",
    "Using sklearn countvectorizer\n",
    "\n",
    "### All words are not equally important, words like the/a/an/is/etc don't tell much about what's going on and so are redundant called \"STOPWORDS\" \n",
    "\n",
    "Remove stopwords before starting text analysis.\n",
    "\n",
    "STEMMER: used to consolidate different words with same stem like repond, responsiveness etc.\n",
    "various stemmers in nltk eg. snowball stemmer and more.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('french')\n",
    "\n",
    "# How many stop words in french nltk corpus\n",
    "print(len(sw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order of operation in Text processing\n",
    "\n",
    "1. Stop words removal\n",
    "2. Stemming\n",
    "3. Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF : \n",
    "Term Frequency: How many times a word occurs in a document.\n",
    "Inverse Document Frequency: In how many document a word occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "1. Select best features\n",
    "2. Engineer new features\n",
    "3. Getting Rid of features\n",
    "\n",
    "## Engineering new Feature:\n",
    "\n",
    "1. Use Human Intuition\n",
    "2. Code up the feature\n",
    "3. Visualize : See if there are trends which can be utilized by ML algos. \n",
    "4. Repeat\n",
    "\n",
    "### Beware of programming bugs that might creep in while engineering new features.\n",
    "\n",
    "1. Anyone can make mistakes--be skeptical of your results!\n",
    "2. 100% accuracy should generally make you suspicious. Extraordinary claims require extraordinary proof.\n",
    "3. If there's a feature that tracks your labels a little too closely, it's very likely a bug!\n",
    "4. If you're sure it's not a bug, you probably don't need machine learning--you can just use that feature alone to assign labels.\n",
    "\n",
    "## Getting Rid of features\n",
    "\n",
    "Remove the feature when:\n",
    "\n",
    "1. It's noisy\n",
    "2. It's highly correlated to other feature. (Repeating information)\n",
    "3. It causes overfitting\n",
    "4. slows down training/testing\n",
    "\n",
    "## General Rule\n",
    "\n",
    "# Features are not equal to information. Features attempt to access information.\n",
    "\n",
    "# Goal: Bare minimum number of features that give the most info.\n",
    "\n",
    "# Univariate Feature Selection:\n",
    "Treats each feature independently and asks how much power it gives you in classifying or regressing.\n",
    "\n",
    "sklearn:\n",
    "\n",
    "1. SelectPercentile: X% of features that are most powerful \n",
    "2. SelectKBest: selects the K features that are most powerful\n",
    "3. TFIDF vectorizer max_df, min_df can also help get the right features. \n",
    "\n",
    "Text data has lots and lots of features , feature reduction can be used.\n",
    "Feature reduction can be used for highly dimensional data. \n",
    "\n",
    "# A classic way to overfit an algorithm is by using lots of features and not a lot of training data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PCA\n",
    "principal component analysis\n",
    "\n",
    "Finds a new coordinate system by shift-rotation of current one to reduce dimensionality.\n",
    "\n",
    "New center is the middle point of old data range and principal axis is the one having significant variation.\n",
    "\n",
    "Gives importance vectors\n",
    "\\\n",
    "Gives spread\n",
    "\n",
    "art of the beauty of PCA is that the data doesn't have to be perfectly 1D in order to find the principal axis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Making composite features using PCA to dimension reduction.\n",
    "\n",
    "In stats : Variance means spread of a data distribution.\n",
    "\n",
    "Principal component direction is the one that has maximum variance(spread). Because only in that direction, information loss is minimized.\n",
    "\n",
    "More the distance of data point from principal component more the information loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA transforms features into principal components.\n",
    "\n",
    "## Principal components are used as new features.\n",
    "\n",
    "## Principal components are perpendicular to each other thus are independent. \n",
    "\n",
    "## Max nof PCs = Nof features\n",
    "\n",
    "\n",
    "## When to use PCA.\n",
    "\n",
    "1. Identifying latent features driving the patterns in the data.\n",
    "2. Dimensionality Reduction.\n",
    "\n",
    "    a. Visualizing High Dimensional data.\n",
    "    \n",
    "    b. Reduce Noise\n",
    "    \n",
    "    c. Make algos work better with fewer inputs. \n",
    "    \n",
    "Higher F1 score better classifier.\n",
    "But more pcs don't mean better classifier, there is an optimal nof pcs that give best results.\n",
    "\n",
    "# Do not perform feature selection before PCA coz it'll throw information away. Feature can be performed after PCA to help improve model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation\n",
    "\n",
    "### Train Test split:\n",
    "\n",
    "splitting data into training and testing sets and using only training set for training and testing set to evaluate the model.\n",
    "\n",
    "1. Serves as a check on overfitting.\n",
    "2. Gives an estimate of performance on independent set.\n",
    "\n",
    "## Flow for split,pca, model training and prediction\n",
    "\n",
    "![title](train_test_pca_svm_flow.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation\n",
    "\n",
    "Dividing the dataset into k subsets, taking each subset as a testing set once and remaining as training set and reporting the average of performance on K subsets. \n",
    "\n",
    "1. Slower to train than train/test split.\n",
    "2. Better estimate of model accuracy than train/test split.\n",
    "\n",
    "Just splits the data irrespective of classes coming in the train/test. This might result into training the model on one class and using it to predict the other which will as we expect perform poorly.\n",
    "\n",
    "## Training data should be such that it has a similar presence of all the classes as in the complete data set. \n",
    "\n",
    "# Stratified K-fold ensures that \n",
    "\n",
    "each set contains approximately the same percentage of samples of each target class as the complete set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "## Classification \n",
    "\n",
    "### accuracy = Nof items in a class predicted correctly/all items in that class.\n",
    "\n",
    "### Recall = When the actual value is positive how often are we correct. \n",
    "\n",
    "### Precision = When predicting positive , how often are we correct. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
